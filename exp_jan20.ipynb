{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Experimentation 100k Tweet Sample: Jan. 20, 2020_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Set-up Path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to storage/ru_disinfo (where data for this project is stored)\n",
    "os.chdir(\"storage/ru_disinfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ru_disinfo\n"
     ]
    }
   ],
   "source": [
    "# assign as Path variable\n",
    "path = Path(os.getcwd())\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load in Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in 100k JSON data from Jan. 19, 2020\n",
    "df = pd.read_json(path/\"100k_tweetsjan19.json\", orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the user_mentions column\n",
    "df.drop(\"user_mentions\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100000 entries, 0 to 99999\n",
      "Data columns (total 10 columns):\n",
      "full_text             100000 non-null object\n",
      "clean_tweet           100000 non-null object\n",
      "label                 100000 non-null object\n",
      "retweet               100000 non-null bool\n",
      "num_mentions          100000 non-null int64\n",
      "mentions_usernames    100000 non-null object\n",
      "num_links             100000 non-null int64\n",
      "vader_compound        100000 non-null float64\n",
      "num_hashtags          100000 non-null int64\n",
      "hashtags_used         100000 non-null object\n",
      "dtypes: bool(1), float64(1), int64(3), object(5)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# check out info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>retweet</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>mentions_usernames</th>\n",
       "      <th>num_links</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtags_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On October 16th, one supporter will get a chan...</td>\n",
       "      <td>october supporter will chance watch debate wit...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG I’ve been dying to tell you about the new ...</td>\n",
       "      <td>been dying tell about cozy collection pajamas ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@skims</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The #SchumerStandard for filling #SCOTUS vacan...</td>\n",
       "      <td>schumer standard filling scotus vacancies</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>#SchumerStandard,#SCOTUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @alicia_keysbr: When someone says #TeamAlic...</td>\n",
       "      <td>when someone says team alicia strongest alread...</td>\n",
       "      <td>verified</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>@alicia_keysbr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>#TeamAlicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Whether it is because of distance, health pro...</td>\n",
       "      <td>whether because distance health problems work ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@NYTParenting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  On October 16th, one supporter will get a chan...   \n",
       "1  OMG I’ve been dying to tell you about the new ...   \n",
       "2  The #SchumerStandard for filling #SCOTUS vacan...   \n",
       "3  RT @alicia_keysbr: When someone says #TeamAlic...   \n",
       "4  “Whether it is because of distance, health pro...   \n",
       "\n",
       "                                         clean_tweet     label  retweet  \\\n",
       "0  october supporter will chance watch debate wit...  verified    False   \n",
       "1  been dying tell about cozy collection pajamas ...  verified    False   \n",
       "2          schumer standard filling scotus vacancies  verified    False   \n",
       "3  when someone says team alicia strongest alread...  verified     True   \n",
       "4  whether because distance health problems work ...  verified    False   \n",
       "\n",
       "   num_mentions mentions_usernames  num_links  vader_compound  num_hashtags  \\\n",
       "0             0                             1           0.204             0   \n",
       "1             1             @skims          2           0.184             0   \n",
       "2             0                             1           0.000             2   \n",
       "3             1     @alicia_keysbr          1           0.248             1   \n",
       "4             1      @NYTParenting          1           0.051             0   \n",
       "\n",
       "              hashtags_used  \n",
       "0                            \n",
       "1                            \n",
       "2  #SchumerStandard,#SCOTUS  \n",
       "3               #TeamAlicia  \n",
       "4                            "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out first few rows\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Focus: Hashtags_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              []\n",
       "1                              []\n",
       "2     [#SchumerStandard, #SCOTUS]\n",
       "3                   [#TeamAlicia]\n",
       "4                              []\n",
       "5                              []\n",
       "6                              []\n",
       "7                          [#AGT]\n",
       "8                              []\n",
       "9                              []\n",
       "10                             []\n",
       "11                             []\n",
       "12                             []\n",
       "13                             []\n",
       "14                             []\n",
       "15                             []\n",
       "16                             []\n",
       "17                             []\n",
       "18           [#dunkin, #worktyme]\n",
       "19                             []\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how we might be able to find all hastags in a given tweet\n",
    "df[\"full_text\"][:20].str.findall(\"#[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with number of hashtags\n",
    "df[\"num_hashtags\"] = df[\"full_text\"].str.findall(\"#[\\w]*\").apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with string value of the hashtags\n",
    "df[\"hashtags_used\"] = df[\"full_text\"].str.findall(\"#[\\w]*\").apply(lambda x: \",\".join([hashtag for hashtag in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Uppercase, Character Count, Word Count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    On October 16th, one supporter will get a chan...\n",
       "1    OMG I’ve been dying to tell you about the new ...\n",
       "2    The #SchumerStandard for filling #SCOTUS vacan...\n",
       "3    RT @alicia_keysbr: When someone says #TeamAlic...\n",
       "4    “Whether it is because of distance, health pro...\n",
       "5    @AndyYork8 What you are saying is \"I was askin...\n",
       "6    QB ➡️ QB respect\\n\\n@DangeRussWilson and @desh...\n",
       "7    “Men lie, Women lie, numbers don’t” Over this ...\n",
       "8    Momentum &amp; energy transfer. Elastic &amp; ...\n",
       "9    RT @TheSource: Bernie Sanders Walks out to You...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"full_text\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        []\n",
       "1     [OMG, I, I, 9AM, PST]\n",
       "2                 [#SCOTUS]\n",
       "3                      [RT]\n",
       "4                        []\n",
       "5                      [\"I]\n",
       "6                  [QB, QB]\n",
       "7                    [#AGT]\n",
       "8                        []\n",
       "9                      [RT]\n",
       "10              [$750M, US]\n",
       "11                   [AIDS]\n",
       "12                   [I, I]\n",
       "13                       []\n",
       "14                       []\n",
       "15                     [RT]\n",
       "16                 [AG,, I]\n",
       "17              [US, \"I, I]\n",
       "18                       []\n",
       "19                       []\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"full_text\"][:20].apply(lambda x: [word for word in x.split() if word.isupper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        []\n",
       "1     [OMG, I, I, 9AM, PST]\n",
       "2                 [#SCOTUS]\n",
       "3                        []\n",
       "4                        []\n",
       "5                      [\"I]\n",
       "6                  [QB, QB]\n",
       "7                    [#AGT]\n",
       "8                        []\n",
       "9                        []\n",
       "10              [$750M, US]\n",
       "11                   [AIDS]\n",
       "12                   [I, I]\n",
       "13                       []\n",
       "14                       []\n",
       "15                       []\n",
       "16                 [AG,, I]\n",
       "17              [US, \"I, I]\n",
       "18                       []\n",
       "19                       []\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the RTs (characters indicating RT\n",
    "df[\"full_text\"][:20].map(lambda x: x.replace(r\"RT|\", \"\").strip()).apply(lambda x: [word for word in x.split() if word.isupper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>retweet</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>mentions_usernames</th>\n",
       "      <th>num_links</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtags_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On October 16th, one supporter will get a chan...</td>\n",
       "      <td>october supporter will chance watch debate wit...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG I’ve been dying to tell you about the new ...</td>\n",
       "      <td>been dying tell about cozy collection pajamas ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@skims</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The #SchumerStandard for filling #SCOTUS vacan...</td>\n",
       "      <td>schumer standard filling scotus vacancies</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>#SchumerStandard,#SCOTUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @alicia_keysbr: When someone says #TeamAlic...</td>\n",
       "      <td>when someone says team alicia strongest alread...</td>\n",
       "      <td>verified</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>@alicia_keysbr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>#TeamAlicia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Whether it is because of distance, health pro...</td>\n",
       "      <td>whether because distance health problems work ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@NYTParenting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  On October 16th, one supporter will get a chan...   \n",
       "1  OMG I’ve been dying to tell you about the new ...   \n",
       "2  The #SchumerStandard for filling #SCOTUS vacan...   \n",
       "3  RT @alicia_keysbr: When someone says #TeamAlic...   \n",
       "4  “Whether it is because of distance, health pro...   \n",
       "\n",
       "                                         clean_tweet     label  retweet  \\\n",
       "0  october supporter will chance watch debate wit...  verified    False   \n",
       "1  been dying tell about cozy collection pajamas ...  verified    False   \n",
       "2          schumer standard filling scotus vacancies  verified    False   \n",
       "3  when someone says team alicia strongest alread...  verified     True   \n",
       "4  whether because distance health problems work ...  verified    False   \n",
       "\n",
       "   num_mentions mentions_usernames  num_links  vader_compound  num_hashtags  \\\n",
       "0             0                             1           0.204             0   \n",
       "1             1             @skims          2           0.184             0   \n",
       "2             0                             1           0.000             2   \n",
       "3             1     @alicia_keysbr          1           0.248             1   \n",
       "4             1      @NYTParenting          1           0.051             0   \n",
       "\n",
       "              hashtags_used  \n",
       "0                            \n",
       "1                            \n",
       "2  #SchumerStandard,#SCOTUS  \n",
       "3               #TeamAlicia  \n",
       "4                            "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "\n",
    "# grab a set of punctuations\n",
    "puncs = string.punctuation\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> RT @alicia_keysbr: When someone says #TeamAlicia is the strongest but we already know that 💁🏽 https://t.co/7MDBKkfYJo\n"
     ]
    }
   ],
   "source": [
    "tweet = df[\"full_text\"][3:4].iloc[0]\n",
    "print(type(tweet), tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def uppercase(text):\n",
    "    \"\"\"\n",
    "    Function that returns number of uppercase letters in tweet.\n",
    "    \"\"\"\n",
    "    # strip Retweet symbol\n",
    "    text = re.sub(r\"RT|#\", \"\", text).strip()\n",
    "    # use spaCy to remove punctuation\n",
    "    doc = nlp(text)\n",
    "    # clean out punctuation\n",
    "    text = \" \".join([token.text for token in doc if not token.is_punct])\n",
    "    # return number of words that start with uppercase\n",
    "    return [word for word in text.split() if word[0].isupper()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When', 'TeamAlicia']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uppercase(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1     10\n",
       "2      3\n",
       "3      2\n",
       "4      3\n",
       "5      2\n",
       "6      4\n",
       "7      5\n",
       "8      7\n",
       "9     11\n",
       "10     3\n",
       "11     6\n",
       "12     4\n",
       "13     1\n",
       "14     1\n",
       "15     4\n",
       "16     9\n",
       "17     6\n",
       "18     3\n",
       "19     4\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"full_text\"][:20].apply(lambda x: len(uppercase(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a356df20f24c98ba68225915841a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# create new column indicating how many uppercase words there were within text\n",
    "df[\"uppercase_words\"] = df[\"full_text\"].progress_apply(lambda x: len(uppercase(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters(raw_text):\n",
    "    \"\"\"\n",
    "    Function that returns number of characters in tweet.\n",
    "    \"\"\"\n",
    "    # strip Retweet symbol (as it isn't included in character count)\n",
    "    text = re.sub(r\"RT\", \"\", raw_text)\n",
    "    # replace links with 23 underscores which serve as placeholders (as all links are 23 characters long, per Twitter)\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '_' * 23, text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4acec3d09243b8b5758f66825634c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     127\n",
       "1     228\n",
       "2      75\n",
       "3     115\n",
       "4     260\n",
       "5     132\n",
       "6     146\n",
       "7     232\n",
       "8     133\n",
       "9     115\n",
       "10     92\n",
       "11    273\n",
       "12    165\n",
       "13     39\n",
       "14     37\n",
       "15    138\n",
       "16    297\n",
       "17    243\n",
       "18     90\n",
       "19    179\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column that counts number of characters in Tweet\n",
    "df[\"full_text\"][:20].progress_apply(lambda x: len(characters(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"full_text\"][16:17].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of observations whose character length is greater than 280: 1.281 %\n"
     ]
    }
   ],
   "source": [
    "text = \"The percentage of observations whose character length is greater than 280:\"\n",
    "\n",
    "print(text, (sum(df[\"full_text\"].apply(lambda x: len(characters(x))) > 280) / len(df)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981e09bb61684b4aa62e824379979bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column that counts number of characters in Tweet\n",
    "df[\"num_characters\"] = df[\"full_text\"].progress_apply(lambda x: len(characters(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_emoji(text):\n",
    "    RE_EMOJI = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "    return RE_EMOJI.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDownloading emoji data ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m (Got response in 0.14 seconds)\n",
      "\u001b[33mWriting emoji data to /root/.demoji/codes.json ...\u001b[0m\n",
      "\u001b[92m... OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install demoji\n",
    "import demoji\n",
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def words(text):\n",
    "    \"\"\"\n",
    "    Function that returns number of words in tweet. (strips RT, digits, mentions)\n",
    "    \"\"\"\n",
    "    # strip Retweet symbol\n",
    "    text = re.sub(r\"RT|&amp|\\d+th|@[\\w]*|http\\S+|\\n\\n|\\n\", \"\", text).strip()\n",
    "    # use spaCy to remove punctuation\n",
    "    doc = nlp(text)\n",
    "    # clean out punctuation\n",
    "    text = \" \".join([token.text for token in doc if not token.is_punct])\n",
    "    # strip emojis from text\n",
    "    text = demoji.replace(text, \"\").strip()\n",
    "    # return average length of words\n",
    "    return round(np.mean([len(word) for word in text.split()]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9167"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3:4][\"full_text\"].apply(words).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a318a7b04b7c4480adb7becc4edf7c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column with the average length of word in text\n",
    "df[\"avg_lenwords\"] = df[\"full_text\"].progress_apply(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>retweet</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>mentions_usernames</th>\n",
       "      <th>num_links</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtags_used</th>\n",
       "      <th>uppercase_words</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>avg_lenwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On October 16th, one supporter will get a chan...</td>\n",
       "      <td>october supporter will chance watch debate wit...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>4.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG I’ve been dying to tell you about the new ...</td>\n",
       "      <td>been dying tell about cozy collection pajamas ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@skims</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>228</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The #SchumerStandard for filling #SCOTUS vacan...</td>\n",
       "      <td>schumer standard filling scotus vacancies</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>#SchumerStandard,#SCOTUS</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>7.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @alicia_keysbr: When someone says #TeamAlic...</td>\n",
       "      <td>when someone says team alicia strongest alread...</td>\n",
       "      <td>verified</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>@alicia_keysbr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>#TeamAlicia</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>4.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Whether it is because of distance, health pro...</td>\n",
       "      <td>whether because distance health problems work ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@NYTParenting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>5.2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  On October 16th, one supporter will get a chan...   \n",
       "1  OMG I’ve been dying to tell you about the new ...   \n",
       "2  The #SchumerStandard for filling #SCOTUS vacan...   \n",
       "3  RT @alicia_keysbr: When someone says #TeamAlic...   \n",
       "4  “Whether it is because of distance, health pro...   \n",
       "\n",
       "                                         clean_tweet     label  retweet  \\\n",
       "0  october supporter will chance watch debate wit...  verified    False   \n",
       "1  been dying tell about cozy collection pajamas ...  verified    False   \n",
       "2          schumer standard filling scotus vacancies  verified    False   \n",
       "3  when someone says team alicia strongest alread...  verified     True   \n",
       "4  whether because distance health problems work ...  verified    False   \n",
       "\n",
       "   num_mentions mentions_usernames  num_links  vader_compound  num_hashtags  \\\n",
       "0             0                             1           0.204             0   \n",
       "1             1             @skims          2           0.184             0   \n",
       "2             0                             1           0.000             2   \n",
       "3             1     @alicia_keysbr          1           0.248             1   \n",
       "4             1      @NYTParenting          1           0.051             0   \n",
       "\n",
       "              hashtags_used  uppercase_words  num_characters  avg_lenwords  \n",
       "0                                          6             127        4.3333  \n",
       "1                                         10             228        4.0000  \n",
       "2  #SchumerStandard,#SCOTUS                3              75        7.1667  \n",
       "3               #TeamAlicia                2             115        4.9167  \n",
       "4                                          3             260        5.2000  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_analyze(text, pos_string):\n",
    "    \"\"\"\n",
    "    Uses spaCy to retrieve data related to an input part-of-speect tag within a tweet.\n",
    "    \"\"\"\n",
    "    # strip Retweet and & symbols\n",
    "    text = re.sub(r\"RT|&amp|http\\S+\", \"\", text).strip()\n",
    "    # create Doc object with tweet\n",
    "    doc = nlp(text)\n",
    "    return len([(token.text, token.pos_) for token in doc if token.pos_ == pos_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5fc3681c594b4e8ea58b4b46c01b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column showing number of nouns in tweet\n",
    "df[\"num_nouns\"] = df[\"full_text\"].progress_apply(lambda x: spacy_analyze(x, \"NOUN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>retweet</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>mentions_usernames</th>\n",
       "      <th>num_links</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtags_used</th>\n",
       "      <th>uppercase_words</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>avg_lenwords</th>\n",
       "      <th>num_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On October 16th, one supporter will get a chan...</td>\n",
       "      <td>october supporter will chance watch debate wit...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>4.3333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG I’ve been dying to tell you about the new ...</td>\n",
       "      <td>been dying tell about cozy collection pajamas ...</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>@skims</td>\n",
       "      <td>2</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>228</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The #SchumerStandard for filling #SCOTUS vacan...</td>\n",
       "      <td>schumer standard filling scotus vacancies</td>\n",
       "      <td>verified</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>#SchumerStandard,#SCOTUS</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>7.1667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @alicia_keysbr: When someone says #TeamAlic...</td>\n",
       "      <td>when someone says team alicia strongest alread...</td>\n",
       "      <td>verified</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>@alicia_keysbr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248</td>\n",
       "      <td>1</td>\n",
       "      <td>#TeamAlicia</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>4.9167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  On October 16th, one supporter will get a chan...   \n",
       "1  OMG I’ve been dying to tell you about the new ...   \n",
       "2  The #SchumerStandard for filling #SCOTUS vacan...   \n",
       "3  RT @alicia_keysbr: When someone says #TeamAlic...   \n",
       "\n",
       "                                         clean_tweet     label  retweet  \\\n",
       "0  october supporter will chance watch debate wit...  verified    False   \n",
       "1  been dying tell about cozy collection pajamas ...  verified    False   \n",
       "2          schumer standard filling scotus vacancies  verified    False   \n",
       "3  when someone says team alicia strongest alread...  verified     True   \n",
       "\n",
       "   num_mentions mentions_usernames  num_links  vader_compound  num_hashtags  \\\n",
       "0             0                             1           0.204             0   \n",
       "1             1             @skims          2           0.184             0   \n",
       "2             0                             1           0.000             2   \n",
       "3             1     @alicia_keysbr          1           0.248             1   \n",
       "\n",
       "              hashtags_used  uppercase_words  num_characters  avg_lenwords  \\\n",
       "0                                          6             127        4.3333   \n",
       "1                                         10             228        4.0000   \n",
       "2  #SchumerStandard,#SCOTUS                3              75        7.1667   \n",
       "3               #TeamAlicia                2             115        4.9167   \n",
       "\n",
       "   num_nouns  \n",
       "0          4  \n",
       "1          8  \n",
       "2          1  \n",
       "3          1  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize columns\n",
    "df = df[\n",
    "    [\"full_text\",\n",
    "     \"clean_tweet\",\n",
    "     \"retweet\",\n",
    "     \"num_mentions\",\n",
    "     \"mentions_usernames\",\n",
    "     \"num_links\",\n",
    "     \"num_hashtags\",\n",
    "     \"hashtags_used\",\n",
    "     \"uppercase_words\",\n",
    "     \"num_characters\",\n",
    "     \"avg_lenwords\", \n",
    "     \"num_nouns\",\n",
    "     \"vader_compound\",\n",
    "     \"label\"\n",
    "    ]\n",
    "       ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"100k_tweetsjan20.json\", orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
