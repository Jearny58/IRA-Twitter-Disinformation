{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Exploration: January 10, 2020_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load in Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "verified = pd.read_json(\"json-data/verified_train.json\", orient=\"split\", dtype={\"id_str\": str})\n",
    "ira = pd.read_json(\"json-data/ira_train.json\", orient=\"split\", dtype={\"id_str\": str}).sample(n=len(verified), random_state=5)\n",
    "\n",
    "# combine dfs above \n",
    "df = pd.concat([verified, ira])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode label column\n",
    "df = pd.get_dummies(df, columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab subset of data to experiment on\n",
    "sample = (df[[\"id_str\", \"screen_name\", \"created_at\", \"full_text\", \"label_real\"]]\n",
    "          .sample(frac=0.50, random_state=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "sample.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Building tf-idf document vectors_\n",
    "\n",
    "- some words occur more commonly across all documents\n",
    "    - give more weight to the words based on account of exclusivity\n",
    "- can help with stopwords, search and recommender systems\n",
    "- also helps with performance\n",
    "- Term frequency-inverse document frequency (TF-IDF)\n",
    "    - proportional to term frequency\n",
    "    - inverse function of the number of documents in which it occurs\n",
    "    - higher weight --> more important in relaying information about document (more exclusive to that document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168883, 221228)\n"
     ]
    }
   ],
   "source": [
    "# import TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# create TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# generate matrix of word vectors\n",
    "tfidf_matrix = vectorizer.fit_transform(sample[\"full_text\"])\n",
    "\n",
    "# print the shape of TFIDF matrix\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Cosine similarity_\n",
    "\n",
    "- the dot product --> consider two vectors, (v^n * w^n)\n",
    "    - magnitude --> sqrt of v^n^2\n",
    "- value is bounded between -1 and 1\n",
    "    - NLP almost always use non-negative weights (value between 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# computing dot product --> initialize numpy vectors\n",
    "A = np.array([1, 3])\n",
    "B = np.array([-2, 2])\n",
    "\n",
    "# compute the dot product \n",
    "dot_prod = np.dot(A, B)\n",
    "\n",
    "# print dot product\n",
    "print(dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.36413198 0.18314713 0.18435251 0.16336438]\n",
      " [0.36413198 1.         0.15054075 0.21704584 0.11203887]\n",
      " [0.18314713 0.15054075 1.         0.21318602 0.07763512]\n",
      " [0.18435251 0.21704584 0.21318602 1.         0.12960089]\n",
      " [0.16336438 0.11203887 0.07763512 0.12960089 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# create test corpus\n",
    "corpus = ['The sun is the largest celestial body in the solar system', \n",
    "          'The solar system consists of the sun and eight revolving planets', \n",
    "          'Ra was the Egyptian Sun God', \n",
    "          'The Pyramids were the pinnacle of Egyptian architecture', \n",
    "          'The quick brown fox jumps over the lazy dog']\n",
    "\n",
    "# initialize TFIDF instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# compute and print the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Building a plot line based recommender_\n",
    "\n",
    "- Text preprocessing\n",
    "- Generate tf-idf vectors\n",
    "- generate cosine similarity matrix\n",
    "- recommender function\n",
    "    - take movie title, cosine similarity matrix and indices series as arguments\n",
    "    - extract pairwise cosine similarity scores for the movie\n",
    "    - sort the scores in descending order\n",
    "    - output titles corresponding to the highest scores\n",
    "    - ignore the highest similarity score\n",
    "- linear_kernel function\n",
    "    - magnitude of tf-idf vector is 1\n",
    "    - cosine score between two tf-idf vectors is their dot product\n",
    "    - can significantly improve computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.36413198 0.18314713 0.18435251 0.16336438]\n",
      " [0.36413198 1.         0.15054075 0.21704584 0.11203887]\n",
      " [0.18314713 0.15054075 1.         0.21318602 0.07763512]\n",
      " [0.18435251 0.21704584 0.21318602 1.         0.12960089]\n",
      " [0.16336438 0.11203887 0.07763512 0.12960089 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# generate cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create small subset of data\n",
    "small_subset = pd.DataFrame(sample[\"full_text\"].sample(n=10000, random_state=5)).reset_index(drop=True)\n",
    "\n",
    "# initialize TFIDF instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# generate the tf-idf vectors for the corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(small_subset[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.01767314 0.00474097 ... 0.         0.03413309 0.02301195]\n",
      " [0.01767314 1.         0.00450859 ... 0.         0.02515418 0.05672451]\n",
      " [0.00474097 0.00450859 1.         ... 0.         0.00674782 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.03413309 0.02515418 0.00674782 ... 0.         1.         0.03275291]\n",
      " [0.02301195 0.05672451 0.         ... 0.         0.03275291 1.        ]]\n",
      "Time taken: 3.372642755508423 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# record start time\n",
    "start = time.time()\n",
    "\n",
    "# compute cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# print cosine similarity matrix\n",
    "print(cosine_sim)\n",
    "\n",
    "# print time taken\n",
    "print(\"Time taken: %s seconds\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.01767314 0.00474097 ... 0.         0.03413309 0.02301195]\n",
      " [0.01767314 1.         0.00450859 ... 0.         0.02515418 0.05672451]\n",
      " [0.00474097 0.00450859 1.         ... 0.         0.00674782 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.03413309 0.02515418 0.00674782 ... 0.         1.         0.03275291]\n",
      " [0.02301195 0.05672451 0.         ... 0.         0.03275291 1.        ]]\n",
      "Time taken: 3.24194598197937 seconds\n"
     ]
    }
   ],
   "source": [
    "# record start time\n",
    "start = time.time()\n",
    "\n",
    "# compute cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# print cosine similarity matrix\n",
    "print(cosine_sim)\n",
    "\n",
    "# Print time taken\n",
    "print(\"Time taken: %s seconds\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mapping between tweets and index\n",
    "indices = pd.Series(small_subset.index, index=small_subset[\"full_text\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(tweet, cosine_sim, indices):\n",
    "    \"\"\"\n",
    "    Function that gets recommended Tweets based off an input Tweet.\n",
    "    \"\"\"\n",
    "    # get index of tweet that matches title\n",
    "    idx = indices[tweet]\n",
    "    # sort the Tweets based on the similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # get the scores for 10 most similar tweets\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    # get the tweet indices\n",
    "    tweet_indices = [i[0] for i in sim_scores]\n",
    "    # return the top 10 most similar tweets\n",
    "    return small_subset[\"full_text\"].iloc[tweet_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What I said on the phone call with the Ukrainian President is “perfectly” stated. There is no reason to call witnesses to analyze my words and meaning. This is just another Democrat Hoax that I have had to live with from the day I got elected (and before!). Disgraceful!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab single tweet from small_subset\n",
    "single_tweet = small_subset.sample(n=1, random_state=5)[\"full_text\"]\n",
    "single_tweet.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TFIDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(small_subset[\"full_text\"])\n",
    "\n",
    "# generate the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# generate recommendations\n",
    "recommends = get_recommendations(single_tweet.iloc[0], cosine_sim, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I said on the phone call with the Ukrainian President is “perfectly” stated. There is no reason to call witnesses to analyze my words and meaning. This is just another Democrat Hoax that I have had to live with from the day I got elected (and before!). Disgraceful!\n"
     ]
    }
   ],
   "source": [
    "print(single_tweet.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#FukushimaAgain The Ukrainian president doesn`t care about anything but money and chocolate!! I'm lost for words! \n",
      "\n",
      "you've got the phone and the number #happy \n",
      "\n",
      "@KatysMyHabibi @katystumblrr meaning I need more space on my phone to do stories cause I'm a secret hoarder. \n",
      "\n",
      "Live fast, live long, always get the foke last word Live hard, live strong, we got the password We opening up the streets, we turning... \n",
      "\n",
      "Just do that \n",
      "\n",
      "No, I just can’t get over you. \n",
      "\n",
      "Another day, another #Senate Democrat #SCOTUS Fact Check. https://t.co/HLzfWQZIfc \n",
      "\n",
      "To many Americans, Memorial Day has lost its meaning https://t.co/wHoEfxF8sM https://t.co/T8bYQeBL77 \n",
      "\n",
      "@AVAETC was on the phone with @tylerperry . Said he had to get off to go tweet with Ava. #ARRAY \n",
      "\n",
      "#Chernobyl2015 #FukushimaAgain Ukrainian president is a fool!! Tosh! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for recommend in recommends:\n",
    "    print(recommend, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
