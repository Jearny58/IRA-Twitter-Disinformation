{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Experimentation on 100k Tweets: January 19, 2020_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load in data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"100k_text.json\", orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On October 16th, one supporter will get a chan...</td>\n",
       "      <td>october supporter will chance watch debate wit...</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMG I‚Äôve been dying to tell you about the new ...</td>\n",
       "      <td>been dying tell about cozy collection pajamas ...</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The #SchumerStandard for filling #SCOTUS vacan...</td>\n",
       "      <td>schumer standard filling scotus vacancies</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @alicia_keysbr: When someone says #TeamAlic...</td>\n",
       "      <td>when someone says team alicia strongest alread...</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‚ÄúWhether it is because of distance, health pro...</td>\n",
       "      <td>whether because distance health problems work ...</td>\n",
       "      <td>verified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  On October 16th, one supporter will get a chan...   \n",
       "1  OMG I‚Äôve been dying to tell you about the new ...   \n",
       "2  The #SchumerStandard for filling #SCOTUS vacan...   \n",
       "3  RT @alicia_keysbr: When someone says #TeamAlic...   \n",
       "4  ‚ÄúWhether it is because of distance, health pro...   \n",
       "\n",
       "                                         clean_tweet     label  \n",
       "0  october supporter will chance watch debate wit...  verified  \n",
       "1  been dying tell about cozy collection pajamas ...  verified  \n",
       "2          schumer standard filling scotus vacancies  verified  \n",
       "3  when someone says team alicia strongest alread...  verified  \n",
       "4  whether because distance health problems work ...  verified  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @alicia_keysbr: When someone says #TeamAlicia is the strongest but we already know that üíÅüèΩ https://t.co/7MDBKkfYJo\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "tweet = df[3:4][\"full_text\"].iloc[0]\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# import string library function  \n",
    "import string  \n",
    "    \n",
    "# Storing the sets of punctuation in variable result  \n",
    "puncs = string.punctuation\n",
    "\n",
    "#stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    53\n",
       "2     7\n",
       "3    16\n",
       "4    35\n",
       "5    23\n",
       "6    21\n",
       "7    40\n",
       "8    17\n",
       "9    17\n",
       "Name: full_text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10][\"full_text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"full_text\"].str.startswith(\"RT\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column indicating if its a retweet or not\n",
    "df[\"retweet\"] = df[\"full_text\"].str.startswith(\"RT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all user mentions\n",
    "df[\"user_mentions\"] = df[\"full_text\"].str.findall(\"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many mentions were there?\n",
    "df[\"num_mentions\"] = df[\"user_mentions\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column that outputs users mention as string with , dividing multiple mentions\n",
    "df[\"mentions_usernames\"] = df[\"user_mentions\"].apply(lambda x: \",\".join([mention for mention in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column of how many links there are\n",
    "df[\"num_links\"] = df[\"full_text\"].str.findall(r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+').apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment(text, sent):\n",
    "    \"\"\"\n",
    "    Gets VADER sentiment for tweet.\n",
    "    \"\"\"\n",
    "    return SentimentIntensityAnalyzer().polarity_scores(text)[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tqdm\n",
    "#!pip install --upgrade spacy\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5771ca43c5304804a18362d33f3639eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# create column with VADER pos score\n",
    "#df[\"vader_compound\"] = df[\"full_text\"].progress_apply(lambda x: sentiment(x, \"compound\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json(\"100k_tweetsjan19.json\", orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordsegment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n",
      "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.8MB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: wordsegment\n",
      "Successfully installed wordsegment-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordsegment\n",
    "from wordsegment import load, segment\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_analyze(text, nlp):\n",
    "    \"\"\"\n",
    "    Spacy analysis of Tweet.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"RT|&amp|\\d+th|@[\\w]*|http\\S+|\\n\\n|\\n\", \"\", text).strip()\n",
    "    doc = nlp(text)\n",
    "    wordlist = [token.text for token in doc if not token.is_punct]\n",
    "    word_len = np.mean([len(token.text) for token in doc if not token.is_punct])\n",
    "    return len(wordlist), word_len, wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n    fi = fo.findall(string)\\n    result = ''\\n    for var in fi:\\n        result += var + ' '\\n    print(result)\\n\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_hashtag(string):\n",
    "    return re.sub(r\"#(\\w+)\", segment(r\"#(\\w+)\"), string)\n",
    "    \n",
    "    \n",
    "\"\"\"    \n",
    "    fi = fo.findall(string)\n",
    "    result = ''\n",
    "    for var in fi:\n",
    "        result += var + ' '\n",
    "    print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[\"full_text\"][2:3].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_hashtag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (18, 4.333333333333333, [On, October, one, sup...\n",
       "1     (50, 3.88, [OMG, I, ‚Äôve, been, dying, to, tell...\n",
       "2     (6, 7.166666666666667, [The, SchumerStandard, ...\n",
       "3     (14, 4.357142857142857, [When, someone, says, ...\n",
       "4     (37, 4.972972972972973, [Whether, it, is, beca...\n",
       "5     (23, 4.0, [What, you, are, saying, is, I, was,...\n",
       "6     (20, 3.65, [QB, ‚û°, Ô∏è, QB, respect, and,  , sho...\n",
       "7     (43, 4.046511627906977, [Men, lie, Women, lie,...\n",
       "8     (16, 6.4375, [Momentum, energy, transfer, Elas...\n",
       "9     (15, 4.2, [Bernie, Sanders, Walks, out, to, Yo...\n",
       "10    (13, 4.230769230769231, [Powerball, numbers, d...\n",
       "11    (45, 4.288888888888889, [The, odds, of, dying,...\n",
       "12    (26, 3.6538461538461537, [I, could, not, be, m...\n",
       "13                      (5, 2.2, [Day, ‚òù, Ô∏è, of, 2019])\n",
       "14                              (2, 4.5, [Patience, ‚è±])\n",
       "15    (26, 3.5384615384615383, [Ron, is, on, a, miss...\n",
       "16    (45, 5.044444444444444, [Betsy, DeVos, 's, own...\n",
       "17    (36, 5.0, [The, president, 's, personal, non, ...\n",
       "18    (16, 4.4375, [Got, the, call, again, from, dun...\n",
       "19    (25, 5.12, [We, 've, studied, all, 100, senato...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"full_text\"][:20].apply(lambda x: spacy_analyze(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     []\n",
       "1                               [@skims]\n",
       "2                                     []\n",
       "3                       [@alicia_keysbr]\n",
       "4                        [@NYTParenting]\n",
       "5                           [@AndyYork8]\n",
       "6     [@DangeRussWilson, @deshaunwatson]\n",
       "7                       [@itsgabrielleu]\n",
       "8                                     []\n",
       "9                           [@TheSource]\n",
       "10                                    []\n",
       "11                         [@GlobalFund]\n",
       "12                    [@jamielynnspears]\n",
       "13                                    []\n",
       "14                                    []\n",
       "15                      [@uninterrupted]\n",
       "16                                    []\n",
       "17                                    []\n",
       "18                                    []\n",
       "19                                    []\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out how many users were mentioned\n",
    "df[\"full_text\"][:20].str.findall(\"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tweet_clean(text):\n",
    "    \"\"\"\n",
    "    Function that preprocesses tweet text.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"RT|&amp\", \"\", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@alicia_keysbr: When someone says #TeamAlicia is the strongest but we already know that üíÅüèΩ https://t.co/7MDBKkfYJo'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_clean(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT aliciakeysbr When someone says TeamAlicia is the strongest but we already know that üíÅüèΩ httpstco7MDBKkfYJo'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to eliminate just punctuation\n",
    "\"\".join([token for token in tweet if token not in puncs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@alicia_keysbr:',\n",
       " 'When',\n",
       " 'someone',\n",
       " 'says',\n",
       " '#TeamAlicia',\n",
       " 'is',\n",
       " 'the',\n",
       " 'strongest',\n",
       " 'but',\n",
       " 'we',\n",
       " 'already',\n",
       " 'know',\n",
       " 'that',\n",
       " 'üíÅüèΩ',\n",
       " 'https://t.co/7MDBKkfYJo']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list comprehension of \n",
    "[word for word in tweet.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
