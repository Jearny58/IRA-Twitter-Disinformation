{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Exploration: January 14, 2020_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Load in Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from Donald Trump's Twitter CSV\n",
    "df = pd.read_csv(\"csv-data/realDonaldTrump.csv\", dtype={\"id_str\": str})\n",
    "\n",
    "# convert created_at column to datetime type\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "\n",
    "# convert lang and source to categorical types\n",
    "df[\"lang\"] = df[\"lang\"].astype(\"category\")\n",
    "df[\"source\"] = df[\"source\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3195 entries, 0 to 3194\n",
      "Data columns (total 9 columns):\n",
      "id_str            3195 non-null object\n",
      "screen_name       3195 non-null object\n",
      "created_at        3195 non-null datetime64[ns]\n",
      "lang              3195 non-null category\n",
      "source            3195 non-null category\n",
      "retweet_count     3195 non-null int64\n",
      "favorite_count    3195 non-null int64\n",
      "is_retweet        3195 non-null bool\n",
      "full_text         3195 non-null object\n",
      "dtypes: bool(1), category(2), datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 159.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1208587674342301703</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2019-12-22 03:18:50</td>\n",
       "      <td>und</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>12003</td>\n",
       "      <td>40784</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/ryVvzb6EGt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1208587342879047681</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2019-12-22 03:17:31</td>\n",
       "      <td>und</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>16688</td>\n",
       "      <td>52784</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/rJ4yo4htsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1208541550424264710</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2019-12-22 00:15:33</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>9966</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>RT @WhiteHouse: LIVE: President @realDonaldTru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1208494102062477312</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2019-12-21 21:07:01</td>\n",
       "      <td>und</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>34484</td>\n",
       "      <td>123089</td>\n",
       "      <td>False</td>\n",
       "      <td>https://t.co/h5bAKuoyV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1208471806815997953</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>2019-12-21 19:38:25</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>29094</td>\n",
       "      <td>143949</td>\n",
       "      <td>False</td>\n",
       "      <td>Last night I was so proud to have signed the l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_str      screen_name          created_at lang  \\\n",
       "0  1208587674342301703  realDonaldTrump 2019-12-22 03:18:50  und   \n",
       "1  1208587342879047681  realDonaldTrump 2019-12-22 03:17:31  und   \n",
       "2  1208541550424264710  realDonaldTrump 2019-12-22 00:15:33   en   \n",
       "3  1208494102062477312  realDonaldTrump 2019-12-21 21:07:01  und   \n",
       "4  1208471806815997953  realDonaldTrump 2019-12-21 19:38:25   en   \n",
       "\n",
       "               source  retweet_count  favorite_count  is_retweet  \\\n",
       "0  Twitter for iPhone          12003           40784       False   \n",
       "1  Twitter for iPhone          16688           52784       False   \n",
       "2  Twitter for iPhone           9966               0        True   \n",
       "3  Twitter for iPhone          34484          123089       False   \n",
       "4  Twitter for iPhone          29094          143949       False   \n",
       "\n",
       "                                           full_text  \n",
       "0                            https://t.co/ryVvzb6EGt  \n",
       "1                            https://t.co/rJ4yo4htsy  \n",
       "2  RT @WhiteHouse: LIVE: President @realDonaldTru...  \n",
       "3                            https://t.co/h5bAKuoyV2  \n",
       "4  Last night I was so proud to have signed the l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last night I was so proud to have signed the largest Defense Bill ever. The very vital Space Force was created. New planes, ships, missiles, rockets and equipment of every kind, and all made right here in the USA. Additionally, we got Border Wall (being built) funding. Nice!\n"
     ]
    }
   ],
   "source": [
    "tweet = df[\"full_text\"][4]\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Continuation of DataCamp Tutorial --> `Advanced NLP with spaCy`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing entity:  iPhone X\n"
     ]
    }
   ],
   "source": [
    "# get the span for iPhone X\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# print the span text\n",
    "print(\"Missing entity: \", iphone_x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last night TIME\n",
      "Space Force ORG\n",
      "USA GPE\n",
      "Border Wall FAC\n"
     ]
    }
   ],
   "source": [
    "# process the text\n",
    "doc = nlp(tweet)\n",
    "\n",
    "# iterate over the tntities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buildings, airports, highways, bridges, etc.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"FAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Rule-based mathcing_\n",
    "\n",
    "- why note just regular expressions?\n",
    "    - match on `Doc` objects, not just strings\n",
    "    - match on tokens and token attributes\n",
    "    - use the model's predictions\n",
    "        - for example find the word \"duck\" only if its a verb (not a noun)\n",
    "- match patterns\n",
    "    - list of dictionaries, one per token\n",
    "    - match exact token texts = `[{\"ORTH\": \"iPhone\"}, {\"ORTH\": \"X\"}]`\n",
    "    - match lexical attributes = `[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]`\n",
    "    - match any token attributes = `[{\"LEMMA\": \"buy\"}, {\"POS\":\"Noun\"}]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "# load a model and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "# initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# add the pattern to the matcher\n",
    "pattern = [{\"ORTH\": \"iPhone\"}, {\"ORTH\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "# process some text\n",
    "doc = nlp(\"New iPhone X relsease date leaked\")\n",
    "# call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "# iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # get matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "# matching lexical attributes\n",
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "# initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# add pattern to matcher\n",
    "matcher.add(\"FIFA\", None, pattern)\n",
    "\n",
    "# create a doc object\n",
    "doc = nlp(\"2018 FIFA World Cup: France won!\")\n",
    "\n",
    "# call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # get matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loved dogs\n",
      "love cats\n"
     ]
    }
   ],
   "source": [
    "# matching other token attributes\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
    "    {\"POS\":\"NOUN\"}\n",
    "]\n",
    "# initialize matcher with shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# add pattern to matcher\n",
    "matcher.add(\"ATTRIBUTES\", None, pattern)\n",
    "\n",
    "# create doc object\n",
    "doc = nlp(\"I loved dogs but not I love cats more.\")\n",
    "\n",
    "# call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # get matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought a smartphone\n",
      "buying apps\n"
     ]
    }
   ],
   "source": [
    "# using operators and quantifiers\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"buy\"},\n",
    "    {\"POS\":\"DET\", \"OP\": \"?\"}, # optional: match 0 or 1 times (!, ?, +, *)\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "# initialize matcher with shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# add pattern to matcher\n",
    "matcher.add(\"QUANT\", None, pattern)\n",
    "\n",
    "# create doc object\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "\n",
    "# call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # get matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: ['iPhone X']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"New iPhone X release date leaked as Apple reveals pre-orders by mistake\")\n",
    "\n",
    "# import matcher and initialize with shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [\n",
    "    {\"TEXT\": \"iPhone\"},\n",
    "    {\"TEXT\": \"X\"}\n",
    "]\n",
    "\n",
    "# add pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", None, pattern)\n",
    "\n",
    "# use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print('Matches:', [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found:  3\n",
      "Match found:  iOS 7\n",
      "Match found:  iOS 11\n",
      "Match found:  iOS 10\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"After making the iOS update you won't notice a radical system-wide redesign: nothing like \n",
    "the aesthetic upheaval we got with iOS 7. Most of iOS 11's furniture remains the same as in iOS 10. But \n",
    "you will discover some tweaks once you delve a little deeper.\"\"\")\n",
    "\n",
    "# write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [\n",
    "    {\"TEXT\": \"iOS\"},\n",
    "    {\"IS_DIGIT\": True}\n",
    "]\n",
    "\n",
    "# add the pattern to the matcher\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found: \", len(matches))\n",
    "\n",
    "# iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found: \", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was \n",
    "downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default \n",
    "program to unpack it... do I also need to download Winzip?\"\"\")\n",
    "\n",
    "# write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [\n",
    "    {\"LEMMA\": \"download\"},\n",
    "    {\"POS\": \"PROPN\"}\n",
    "]\n",
    "\n",
    "# add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found:  5\n",
      "Match found:  beautiful design\n",
      "Match found:  smart search\n",
      "Match found:  automatic labels\n",
      "Match found:  optional voice\n",
      "Match found:  optional voice responses\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"\"\"Features of the app include a beautiful design, \n",
    "smart search, automatic labels and optional voice responses.\"\"\")\n",
    "\n",
    "# write a pattern for adjective plus one or two nouns\n",
    "pattern = [\n",
    "    {\"POS\": \"ADJ\"},\n",
    "    {\"POS\": \"NOUN\"},\n",
    "    {\"POS\": \"NOUN\", \"OP\": \"?\"}\n",
    "]\n",
    "\n",
    "# add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", None, pattern)\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found: \", len(matches))\n",
    "\n",
    "# iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found: \", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
